{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFz8NQRi6WW0",
        "outputId": "63d7075d-284e-45f9-8370-925f2cf148b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tuning Logistic Regression...\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best Logistic Regression params: {'C': np.float64(9.842308858067883), 'max_iter': 200, 'penalty': 'l2', 'solver': 'saga'}\n",
            "\n",
            "Tuning Random Forest...\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
            "Best Random Forest params: {'bootstrap': False, 'max_depth': 37, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 125}\n",
            "\n",
            "Evaluating Logistic Regression with best hyperparameters:\n",
            "  On TRAIN set:\n",
            "    Accuracy: 0.9985\n",
            "    Precision: 0.9985\n",
            "    Recall: 0.9985\n",
            "    F1 Score: 0.9985\n",
            "  On train3 subset:\n",
            "    Accuracy: 0.9975\n",
            "    Precision: 0.9976\n",
            "    Recall: 0.9975\n",
            "    F1 Score: 0.9975\n",
            "  On Test 1:\n",
            "    Accuracy: 0.6141\n",
            "    Precision: 0.5680\n",
            "    Recall: 0.6141\n",
            "    F1 Score: 0.5863\n",
            "  On Test 2:\n",
            "    Accuracy: 0.6208\n",
            "    Precision: 0.5958\n",
            "    Recall: 0.6208\n",
            "    F1 Score: 0.6028\n",
            "  On Test 3:\n",
            "    Accuracy: 0.6227\n",
            "    Precision: 0.5619\n",
            "    Recall: 0.6227\n",
            "    F1 Score: 0.5841\n",
            "\n",
            "Evaluating Random Forest with best hyperparameters:\n",
            "  On TRAIN set:\n",
            "    Accuracy: 0.6929\n",
            "    Precision: 0.8051\n",
            "    Recall: 0.6929\n",
            "    F1 Score: 0.6462\n",
            "  On train3 subset:\n",
            "    Accuracy: 0.6373\n",
            "    Precision: 0.7959\n",
            "    Recall: 0.6373\n",
            "    F1 Score: 0.5857\n",
            "  On Test 1:\n",
            "    Accuracy: 0.6003\n",
            "    Precision: 0.5250\n",
            "    Recall: 0.6003\n",
            "    F1 Score: 0.4773\n",
            "  On Test 2:\n",
            "    Accuracy: 0.5992\n",
            "    Precision: 0.5679\n",
            "    Recall: 0.5992\n",
            "    F1 Score: 0.4719\n",
            "  On Test 3:\n",
            "    Accuracy: 0.6537\n",
            "    Precision: 0.5147\n",
            "    Recall: 0.6537\n",
            "    F1 Score: 0.5276\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Load data (same as before)\n",
        "train1 = pd.read_csv('train-1.csv')\n",
        "train2 = pd.read_csv('train-2.csv')\n",
        "train3 = pd.read_csv('train-3.csv')\n",
        "TRAIN = pd.concat([train1, train2, train3], ignore_index=True)\n",
        "\n",
        "test1 = pd.read_csv('test-1.csv')\n",
        "test2 = pd.read_csv('test-2.csv')\n",
        "test3 = pd.read_csv('test-3.csv')\n",
        "\n",
        "X_train = TRAIN[\"Sentence\"]\n",
        "y_train = TRAIN[\"Label\"]\n",
        "\n",
        "X_train3 = train3[\"Sentence\"]\n",
        "y_train3 = train3[\"Label\"]\n",
        "\n",
        "X_test1 = test1[\"Sentence\"]\n",
        "y_test1 = test1[\"Label\"]\n",
        "\n",
        "X_test2 = test2[\"Sentence\"]\n",
        "y_test2 = test2[\"Label\"]\n",
        "\n",
        "X_test3 = test3[\"Sentence\"]\n",
        "y_test3 = test3[\"Label\"]\n",
        "\n",
        "# Vectorize text data\n",
        "vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1,2), stop_words='english')\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_train3_vec = vectorizer.transform(X_train3)\n",
        "X_test1_vec = vectorizer.transform(X_test1)\n",
        "X_test2_vec = vectorizer.transform(X_test2)\n",
        "X_test3_vec = vectorizer.transform(X_test3)\n",
        "\n",
        "# Define models and hyperparameter distributions for RandomizedSearchCV\n",
        "param_dist_logreg = {\n",
        "    'C': uniform(0.01, 10),          # Regularization strength between 0.01 and 10\n",
        "    'penalty': ['l2'],               # 'l1' can be used with saga, but l2 is more stable\n",
        "    'solver': ['saga'],              # saga supports l1 and l2, good for sparse data\n",
        "    'max_iter': [200, 300, 400]\n",
        "}\n",
        "\n",
        "param_dist_rf = {\n",
        "    'n_estimators': randint(50, 150),    # Number of trees between 50 and 150\n",
        "    'max_depth': randint(10, 40),        # Max depth between 10 and 40\n",
        "    'min_samples_split': randint(2, 10), # Minimum samples to split nodes\n",
        "    'min_samples_leaf': randint(1, 5),   # Minimum samples at leaf nodes\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Setup RandomizedSearchCV for Logistic Regression\n",
        "logreg = LogisticRegression(random_state=42, n_jobs=-1)\n",
        "rs_logreg = RandomizedSearchCV(\n",
        "    logreg, param_distributions=param_dist_logreg,\n",
        "    n_iter=20, scoring='f1_weighted', cv=3, verbose=2, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Setup RandomizedSearchCV for Random Forest\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "rs_rf = RandomizedSearchCV(\n",
        "    rf, param_distributions=param_dist_rf,\n",
        "    n_iter=20, scoring='f1_weighted', cv=3, verbose=2, random_state=42, n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit and tune Logistic Regression\n",
        "print(\"Tuning Logistic Regression...\")\n",
        "rs_logreg.fit(X_train_vec, y_train)\n",
        "print(\"Best Logistic Regression params:\", rs_logreg.best_params_)\n",
        "\n",
        "# Fit and tune Random Forest\n",
        "print(\"\\nTuning Random Forest...\")\n",
        "rs_rf.fit(X_train_vec, y_train)\n",
        "print(\"Best Random Forest params:\", rs_rf.best_params_)\n",
        "\n",
        "# Function to evaluate model on multiple datasets\n",
        "def evaluate_model(name, model, X_train, y_train, X_train3, y_train3, X_tests, y_tests, test_names):\n",
        "    print(f\"\\nEvaluating {name} with best hyperparameters:\")\n",
        "    y_pred_train = model.predict(X_train)\n",
        "    print(\"  On TRAIN set:\")\n",
        "    print(f\"    Accuracy: {accuracy_score(y_train, y_pred_train):.4f}\")\n",
        "    print(f\"    Precision: {precision_score(y_train, y_pred_train, average='weighted'):.4f}\")\n",
        "    print(f\"    Recall: {recall_score(y_train, y_pred_train, average='weighted'):.4f}\")\n",
        "    print(f\"    F1 Score: {f1_score(y_train, y_pred_train, average='weighted'):.4f}\")\n",
        "\n",
        "    y_pred_train3 = model.predict(X_train3)\n",
        "    print(\"  On train3 subset:\")\n",
        "    print(f\"    Accuracy: {accuracy_score(y_train3, y_pred_train3):.4f}\")\n",
        "    print(f\"    Precision: {precision_score(y_train3, y_pred_train3, average='weighted'):.4f}\")\n",
        "    print(f\"    Recall: {recall_score(y_train3, y_pred_train3, average='weighted'):.4f}\")\n",
        "    print(f\"    F1 Score: {f1_score(y_train3, y_pred_train3, average='weighted'):.4f}\")\n",
        "\n",
        "    for X_test, y_test, tname in zip(X_tests, y_tests, test_names):\n",
        "        y_pred_test = model.predict(X_test)\n",
        "        print(f\"  On {tname}:\")\n",
        "        print(f\"    Accuracy: {accuracy_score(y_test, y_pred_test):.4f}\")\n",
        "        print(f\"    Precision: {precision_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
        "        print(f\"    Recall: {recall_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
        "        print(f\"    F1 Score: {f1_score(y_test, y_pred_test, average='weighted'):.4f}\")\n",
        "\n",
        "# Prepare test sets and names\n",
        "test_sets = [X_test1_vec, X_test2_vec, X_test3_vec]\n",
        "test_labels = [y_test1, y_test2, y_test3]\n",
        "test_names = ['Test 1', 'Test 2', 'Test 3']\n",
        "\n",
        "# Evaluate Logistic Regression best model\n",
        "best_logreg = rs_logreg.best_estimator_\n",
        "evaluate_model(\"Logistic Regression\", best_logreg, X_train_vec, y_train, X_train3_vec, y_train3, test_sets, test_labels, test_names)\n",
        "\n",
        "# Evaluate Random Forest best model\n",
        "best_rf = rs_rf.best_estimator_\n",
        "evaluate_model(\"Random Forest\", best_rf, X_train_vec, y_train, X_train3_vec, y_train3, test_sets, test_labels, test_names)\n"
      ]
    }
  ]
}